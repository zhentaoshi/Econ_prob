{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Space\n",
    "\n",
    "\n",
    "A *sample space* $\\Omega$ is a collection of all possible outcomes. It is a set of things.\n",
    "\n",
    "An *event* $A$ is a subset of $\\Omega$. It is something of interest on the sample space.\n",
    "\n",
    "A $\\sigma$-*field* is a complete set of events that includes all countably finite unions, interactions, and differences.\n",
    "It is a well-organized structure built on the sample space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A *probability measure* satisfies\n",
    "\n",
    "* (positiveness) $P\\left(A\\right)\\geq0$ for all events;\n",
    "* (countable additivity) if $A_{i}$, $i\\in\\mathbb{N}$, are \n",
    "are mutually disjoint, then\n",
    "$P\\left(\\bigcup_{i\\in\\mathbb{N}}A_{i}\\right)=\\sum_{i\\in\\mathbb{N}}\\mu\\left(A_{i}\\right).$\n",
    "* $P(\\Omega) = 1$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Example**: (probability measure) Personal wealth management: asset allocation.\n",
    "A probability function is not necessarily about uncertainty. Two allocation rules: 1. Equal weight. 2. Optimal weight.\n",
    "\n",
    "So far we have answered the question: \"What is a well-defined probability?\", but we have not yet\n",
    "answered \"How to assign the probability?\"\n",
    "\n",
    "There are two major schools of thinking on probability assignement. One is\n",
    "*frequentist*, who considers probability as the average chance of occurrence if a large number of experiments\n",
    "are carried out. The other is *Bayesian*, who deems probability as a subjective brief.\n",
    "The principles of these two schools are largely incompatible, while each school has\n",
    "peculiar merit under different context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Variable\n",
    "\n",
    "*Random variable* maps events to a real number. If the outcome is multivariate, we call it a *random vector*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data example**\n",
    "\n",
    "Data source: [HK top 300 Youtubers](https://www.kaggle.com/datasets/patriotboy112/hks-top-300-youtubers). We look at the number of uploaded videos in these accounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "d0 = readr::read_csv(\"HKTop300YouTubers.csv\")\n",
    "print(d0)\n",
    "\n",
    "library(magrittr)\n",
    "\n",
    "# remove NA and zeros\n",
    "d0[ d0 == 0 ] <- NA\n",
    "sel <- d0 %>% is.na( ) %>% apply( 1, any)\n",
    "d0 %<>% dplyr::filter( !sel )\n",
    "\n",
    "d1 <- d0 %>% dplyr::select(3:5)\n",
    "names(d1) <- c(\"subs\", \"view\", \"count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "print( d1[[\"count\"]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "hist(d1[[\"count\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "d1.log <- log(d1)\n",
    "hist(d1.log[[\"count\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution Function\n",
    "\n",
    "We go back to some terms that we have learned in a undergraduate\n",
    "probability course. A *(cumulative) distribution function*\n",
    "$F:\\mathbb{R}\\mapsto [0,1]$ is defined as\n",
    "$$F\\left(x\\right)=P\\left(X\\leq x\\right)=\n",
    "P\\left(\\{X\\leq x\\}\\right).$$\n",
    "It is often abbreviated as CDF, and it has the following properties.\n",
    "\n",
    "* $\\lim_{x\\to-\\infty}F\\left(x\\right)=0$,\n",
    "* $\\lim_{x\\to\\infty}F\\left(x\\right)=1$,\n",
    "* non-decreasing,\n",
    "* right-continuous $\\lim_{y\\to x^{+}}F\\left(y\\right)=F\\left(x\\right).$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "plot(ecdf(d1.log[[\"count\"]]), verticals = TRUE, do.points = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the definitions of quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "quantile(d1.log[[\"count\"]], probs = 1:4/4 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For continuous distribution, if there exists a function $f$ such that for all $x$,\n",
    "$$F\\left(x\\right)=\\int_{-\\infty}^{x}f\\left(y\\right)dy,$$\n",
    " then $f$ is\n",
    "    called the *probability density function* of $X$, often abbreviated as PDF.\n",
    "It is easy to show that $f\\left(x\\right)\\geq0$ and\n",
    "    $\\int_{a}^{b}f\\left(x\\right)dx=F\\left(b\\right)-F\\left(a\\right)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Example** We have learned many parametric distributions like the binary distribution, the Poisson distribution,\n",
    "the uniform distribution, the normal distribution, $\\chi^{2}$, $t$, $F$ and so on.\n",
    "They are parametric distributions, meaning that the CDF or PDF can be completely\n",
    "characterized by a few parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Example** `R` has a rich collection of distributions implemented in a unified rule:\n",
    "`d` for density, `p` for probability, `q` for quantile, and `r` for random variable generation.\n",
    "For instance, `dnorm`, `pnorm`, `qnorm`, and `rnorm` are the corresponding functions of the normal distribution, and the parameters $\\mu$ and $\\sigma$ can be specified in the arguments of the functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "qnorm(0.975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "pnorm(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "dnorm(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "rnorm(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "rpois(2, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Below is a piece of `R` code for demonstration.\n",
    "\n",
    "1. Plot the density of standard normal distribution over an equally spaced grid system `x_axis = seq(-3, 3, by = 0.01)` (black line).\n",
    "2. Generate 1000 observations for $N(0,1)$. Plot the kernel density, a nonparametric estimation of the density (red line).\n",
    "3. Calculate the 95th quantile and the empirical probability of observing a value greater than the 95th quantile.\n",
    "In population, this value is 5%. What is the number coming out of this experiment?\n",
    "\n",
    "(Since we do not fix the random seed in the computer, the outcome is slightly different each time we run the code.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "x_axis = seq(-3, 3, by = 0.01)\n",
    "\n",
    "y = dnorm(x_axis)\n",
    "plot(y = y, x=x_axis, type = \"l\", xlab = \"value\", ylab = \"density\")\n",
    "z = rnorm(1000)\n",
    "lines( density(z), col = \"red\")\n",
    "crit = qnorm(.95)\n",
    "\n",
    "cat(\"the empirical rejection probability is\", mean( z > crit ), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration\n",
    "\n",
    "An integral\n",
    "$\\int X\\mathrm{d}P$ is called the *expected value,* or\n",
    "*expectation,* of $X$. We often use the notation\n",
    "$E\\left[X\\right]$, instead of $\\int X\\mathrm{d}P$, for convenience.\n",
    "\n",
    "Expectation provides the average of a random variable,\n",
    "despite that we cannot foresee the realization of a random variable in a particular trial\n",
    "(otherwise the study of uncertainty is trivial). In the frequentist's view,\n",
    "the expectation is the average outcome if we carry out a large number of independent\n",
    "trials.\n",
    "\n",
    "If we know the probability mass function of a discrete random variable, its expectation\n",
    "is calculated as $E\\left[X\\right]=\\sum_{x}xP\\left(X=x\\right)$, which is\n",
    "the integral of a simple function.\n",
    "If a continuous random variable has a PDF $f(x)$, its expectation\n",
    "can be computed as  $E\\left[X\\right]=\\int xf\\left(x\\right)\\mathrm{d}x$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "mean( d1.log[[\"count\"]] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here are some properties of the expectation.\n",
    "\n",
    "\n",
    "-  The probability of an event $A$ is the expectation\n",
    "of an indicator function. $E\\left[1\\left\\{ A\\right\\}  \\right]= 1\\times P(A) + 0 \\times P(A^c) =P\\left(A\\right)$.\n",
    "\n",
    "-   $E\\left[X^{r}\\right]$ is call the $r$-moment of $X$. The *mean* of a random variable is the first moment $\\mu=E\\left[X\\right]$, and\n",
    "the second *centered* moment is called the *variance*\n",
    "$\\mathrm{var}\\left[X\\right]=E\\left[\\left(X-\\mu\\right)^{2}\\right]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "var(d1.log[[\"count\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The third centered moment $E\\left[\\left(X-\\mu\\right)^{3}\\right]$,\n",
    "called *skewness*, is a measurement of the\n",
    "symmetry of a random variable, and the fourth centered moment\n",
    "    $E\\left[\\left(X-\\mu\\right)^{4}\\right]$, called *kurtosis*, is\n",
    "     a measurement of the tail thickness.\n",
    "\n",
    "- We call\n",
    "    $E\\left[\\left(X-\\mu\\right)^{3}\\right]/\\sigma^{3}$ the *skewness coefficient*, and\n",
    "    $E\\left[\\left(X-\\mu\\right)^{4}\\right]/\\sigma^{4}-3$ *degree of excess*. A normal distribution's  skewness and  degree of excess are both zero.\n",
    "\n",
    "    -   **Application**: [The formula that killed Wall\n",
    "        Street](http://archive.wired.com/techbiz/it/magazine/17-03/wp_quant?currentPage=all)\n",
    "\n",
    "- Moments do not always exist. For example, the mean of the Cauchy distribution does not exist,\n",
    "and the variance of the $t(2)$ distribution does not exist.\n",
    "\n",
    "- $E[\\cdot]$ is a linear operation. If $\\phi(\\cdot)$ is a linear function, then $E[\\phi(X)] = \\phi(E[X]).$\n",
    "\n",
    "-   *Jensen's inequality* is an important fact.\n",
    "A function $\\varphi(\\cdot)$ is convex if\n",
    "$\\varphi( a x_1 + (1-a) x_2 ) \\leq a \\varphi(x_1) + (1-a) \\varphi(x_2)$ for all $x_1,x_2$\n",
    "in the domain and $a\\in[0,1]$. For instance, $x^2$ is a convex function.\n",
    "Jensen's inequality says that if $\\varphi\\left(\\cdot\\right)$ is a convex\n",
    "    function, then\n",
    "    $\\varphi\\left(E\\left[X\\right]\\right)\\leq E\\left[\\varphi\\left(X\\right)\\right].$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Markov inequality* is another simple but important fact. If $E\\left[\\left|X\\right|^{r}\\right]$ exists,\n",
    "    then\n",
    "    $P\\left(\\left|X\\right|>\\epsilon\\right)\\leq E\\left[\\left|X\\right|^{r}\\right]/\\epsilon^{r}$\n",
    "    for all $r\\geq1$. *Chebyshev inequality* $P\\left(\\left|X\\right|>\\epsilon\\right)\\leq E\\left[X^{2}\\right]/\\epsilon^{2}$\n",
    "    is a special case of the Markov inequality when $r=2$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Random Variable\n",
    "\n",
    "A bivariate random variable is a\n",
    "measurable function $X:\\Omega\\mapsto\\mathbb{R}^{2}$, and more generally a multivariate random\n",
    "variable is a measurable function $X:\\Omega\\mapsto\\mathbb{R}^{n}$.\n",
    "We can define the *joint CDF* as\n",
    "$F\\left(x_{1},\\ldots,x_{n}\\right)=P\\left(X_{1}\\leq x_{1},\\ldots,X_{n}\\leq x_{n}\\right)$.\n",
    "Joint PDF is defined similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "plot(d1.log$subs, d1.log$view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It is sufficient to introduce the joint distribution, conditional distribution\n",
    "and marginal distribution in the simple bivariate case, and these definitions\n",
    "can be extended to multivariate distributions. Suppose\n",
    "a bivariate random variable $(X,Y)$ has a joint density\n",
    "$f(\\cdot,\\cdot)$.\n",
    "The  *conditional density* can be roughly written as  $f\\left(y|x\\right)=f\\left(x,y\\right)/f\\left(x\\right)$ if we do not formally deal\n",
    "with the case $f(x)=0$.\n",
    "The *marginal density* $f\\left(y\\right)=\\int f\\left(x,y\\right)dx$ integrates out\n",
    "the coordinate that is not interested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independence\n",
    "\n",
    "In a probability space $(\\Omega, \\mathcal{F}, P)$, for two events $A_1,A_2\\in \\mathcal{F}$ the *conditional probability* is\n",
    "\n",
    "$$P\\left(A_1|A_2\\right) = \\frac{P\\left(A_1 A_2\\right)}{ P\\left(A_2\\right) }.$$ \n",
    "\n",
    "In the definition of conditional probability, $A_2$ plays\n",
    "the role of the outcome space  so that\n",
    " $P(A_1 A_2)$ is standardized by the total mass $P(A_2)$.\n",
    "\n",
    "Since $A_1$ and $A_2$ are symmetric, we also have $P(A_1 A_2) = P(A_2|A_1)P(A_1)$.\n",
    "It implies\n",
    "$$P(A_1 | A_2)=\\frac{P\\left(A_2| A_1\\right)P\\left(A_1\\right)}{P\\left(A_2\\right)}$$\n",
    "This formula is the well-known *Bayes' Theorem*. It is particularly important in\n",
    "decision theory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Example:** $A_1$ is the event \"a student can survive CUHK's MSc program\", and $A_2$ is\n",
    "his or her application profile.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We say two events $A_1$ and $A_2$ are *independent* if $P(A_1A_2) = P(A_1)P(A_2)$.\n",
    "If $P(A_2) \\neq 0$, it is equivalent to $P(A_1 | A_2 ) = P(A_1)$.\n",
    "In words, knowing $A_2$ does not change the probability of $A_1$.\n",
    "\n",
    "If $X$ and $Y$ are independent, $E[XY] = E[X]E[Y]$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "Y <- matrix(rnorm(200), ncol = 2)\n",
    "plot(x = Y[, 1], y = Y[, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "Y <- matrix(rnorm(200), ncol = 2) %*% matrix( c(1, 0.5, 0.5, 1), 2 )\n",
    "plot(x = Y[, 1], y = Y[, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Application**: (Chebyshev law of large numbers) If\n",
    "$X_{1},X_{2},\\ldots,X_{n}$ are independent, and they have the same mean\n",
    "$0$ and variance $\\sigma^{2}<\\infty$. Let\n",
    "$Z_{n}=\\frac{1}{n}\\sum_{i=1}^{n} X_{i}$. Then the\n",
    "probability $P\\left(\\left|Z_{n}\\right|>\\epsilon\\right)\\to0$ as\n",
    "$n\\to\\infty$.\n",
    "\n",
    "The culmination of probability theory is *law of large numbers* and\n",
    "*central limit theorem*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Law of Iterated Expectations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In the bivariate case, if the conditional density exists, the conditional expectation can be computed as\n",
    "    $E\\left[Y|X\\right]=\\int yf\\left(y|X\\right)dy$.\n",
    "The law of iterated expectation implies $E\\left[E\\left[Y|X\\right]\\right]=E\\left[Y\\right]$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "dx <- d1.log %>% \n",
    "  tibble::add_column(category = d0$category) %>%\n",
    "  dplyr::group_by(category) %>%\n",
    "  dplyr::summarize(mean = mean(count), no = dplyr::n() )\n",
    "print(dx)\n",
    "\n",
    "print( sum( dx$mean * ( dx$no/nrow(d1.log) ) ) ) # average over categories\n",
    "print( mean(d1.log[[\"count\"]])) # overall average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Below are some properties of conditional expectations\n",
    "\n",
    "1.  $E\\left[E\\left[Y|X_{1},X_{2}\\right]|X_{1}\\right]=E\\left[Y|X_{1}\\right];$\n",
    "2.  $E\\left[E\\left[Y|X_{1}\\right]|X_{1},X_{2}\\right]=E\\left[Y|X_{1}\\right];$\n",
    "3.  $E\\left[h\\left(X\\right)Y|X\\right]=h\\left(X\\right)E\\left[Y|X\\right].$\n",
    "\n",
    "**Application**: Regression is a technique that decomposes a random variable $Y$\n",
    "into two parts, a conditional mean and a residual. Write\n",
    " $Y=E\\left[Y|X\\right]+\\epsilon$, where\n",
    "$\\epsilon=Y-E\\left[Y|X\\right]$. Show that $E[\\epsilon] = 0$ and  $E[\\epsilon E[Y|X] ] = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# readr::write_csv(d1.log, file = \"logYoutuber.csv\")\n",
    "save(d1.log, file = \"logYoutuber.Rdata\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R [conda env:r]",
   "language": "R",
   "name": "conda-env-r-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
