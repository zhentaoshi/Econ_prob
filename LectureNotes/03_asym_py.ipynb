{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f1635d2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Asymptotics\n",
    "\n",
    "<!-- QL covers basic asymptotic theory -->\n",
    "\n",
    "Asymptotic theory is a set of mathematical tools that invoke limits to simplify our understanding of the behavior of statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93896fe2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## Modes of Convergence\n",
    "\n",
    "Let $x_{1},x_{2},\\ldots$ be a (countably) infinite\n",
    "sequence of non-random variables.\n",
    "*Convergence* of this non-random sequence means that for any\n",
    "$\\varepsilon>0$, there exists an $N\\left(\\varepsilon\\right)$ such that\n",
    "for all $n>N\\left(\\varepsilon\\right)$, we have\n",
    "$\\left|x_{n}-x\\right|<\\varepsilon.$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7323ca",
   "metadata": {},
   "source": [
    "**Example**\n",
    "\n",
    "$x_{1,n} = 1 + 1/n$ is a sequence, with limit 1. $x_{2,n} = - \\exp(-n)$ is another sequence, with limit 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39117b0e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We learned limits of deterministic sequences in high school. \n",
    "Now, we discuss convergence of a sequence of random variables. Since a random variable\n",
    "is “random”, we must be clear what *convergence* means. Several modes of\n",
    "convergence are widely used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e77791e",
   "metadata": {},
   "source": [
    "\n",
    "We say a sequence of random variables $\\left(x_{n}\\right)$ *converges in\n",
    "probability* to $x$, where $x$ can be either a random variable or a\n",
    "non-random constant, if for any $\\varepsilon>0$ the probability\n",
    "\n",
    "$$\n",
    "P\\left\\{ \\left|x_{n} -x\\right|\\geq\\varepsilon\\right\\} \\to0\n",
    "$$\n",
    "\n",
    "as $n\\to\\infty$. We write $x_{n}\\stackrel{p}{\\to}x$ or\n",
    "$\\mathrm{plim}_{n\\to\\infty}x_{n}=x$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b108de",
   "metadata": {},
   "source": [
    "\n",
    "A sequence of random variables $\\left(x_{n}\\right)$ *converges in\n",
    "squared-mean* to $x$, where $x$ can be either a random variable or a\n",
    "non-random constant, if $E\\left[\\left(x_{n}-x\\right)^{2}\\right]\\to0.$ It\n",
    "is denoted as $x_{n}\\stackrel{m.s.}{\\to}x$.\n",
    "\n",
    "In these definitions either\n",
    "$P\\left\\{ \\left|x_{n}-x\\right|>\\varepsilon\\right\\}$\n",
    "or $E\\left[\\left(x_{n}-x\\right)^{2}\\right]$ is a non-random quantity,\n",
    "and it thus converges to 0 as a non-random sequence under the standard \n",
    "meaning of \"$\\to$\".\n",
    "\n",
    "Squared-mean convergence is stronger than convergence in probability.\n",
    "That is, $x_{n}\\stackrel{m.s.}{\\to}x$ implies $x_{n}\\stackrel{p}{\\to}x$\n",
    "but the converse is untrue. Here is an example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f8e8fd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Example**\n",
    "\n",
    "$(x_{n})$ is a sequence\n",
    "of binary random variables: $x_{n}=\\sqrt{n}$ with probability $1/n$, and\n",
    "$x_{n}=0$ with probability $1-1/n$. Then $x_{n}\\stackrel{p}{\\to}0$ but\n",
    "$x_{n}\\stackrel{m.s.}{\\nrightarrow}0$. To verify these claims, notice\n",
    "that for any $\\varepsilon>0$, we have\n",
    "$P\\left(\\left|x_{n}-0\\right|<\\varepsilon\\right)=P\\left(x_{n}=0\\right)=1-1/n\\rightarrow1$\n",
    "and thereby $x_{n}\\stackrel{p}{\\to}0$. On the other hand,\n",
    "$E\\left[\\left(x_{n}-0\\right)^{2}\\right]=n\\cdot1/n+0\\cdot(1-1/n)=1\\nrightarrow0,$\n",
    "so $x_{n}\\stackrel{m.s.}{\\nrightarrow}0$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8d9d30",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "This example \n",
    "highlights the difference between the two modes of convergence.\n",
    "Convergence in probability does not take account extreme events with small probability. \n",
    "Squared-mean convergence, instead, deals\n",
    "with the average over the entire probability space. If a random variable\n",
    "can take a wild value, with small probability though, it may blow away\n",
    "the squared-mean convergence. On the contrary, such irregularity does\n",
    "not destroy convergence in probability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea7deae",
   "metadata": {},
   "source": [
    "\n",
    "Both convergence in probability and squared-mean convergence are about\n",
    "convergence of random variables to a target random variable or constant.\n",
    "That is, the distribution of $(x_{n}-x)$ is concentrated around 0 as\n",
    "$n\\to\\infty$. *Convergence in distribution* is, however, about the\n",
    "convergence of CDF, instead of the random variable. \n",
    "\n",
    "Let\n",
    "$F_{n}\\left(\\cdot\\right)$ be the CDF of $x_{n}$ and\n",
    "$F\\left(\\cdot\\right)$ be the CDF of $x$.\n",
    "We say a sequence of random variables $\\left(x_{n}\\right)$ converges in\n",
    "distribution to a random variable $x$ if\n",
    "$F_{n}\\left(a\\right)\\to F\\left(a\\right)$ as $n\\to\\infty$ at each\n",
    "point $a\\in\\mathbb{R}$ where $F\\left(\\cdot\\right)$ is\n",
    "continuous. We write $x_{n}\\stackrel{d}{\\to}x$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3267daca",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "Convergence in distribution is the weakest mode. If\n",
    "$x_{n}\\stackrel{p}{\\to}x$, then $x_{n}\\stackrel{d}{\\to}x$. The converse\n",
    "is untrue in general, unless $x$ is a non-random constant (A constant\n",
    "$x$ can be viewed as a degenerate random variables.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa44c77",
   "metadata": {},
   "source": [
    "**Example**\n",
    "\n",
    "Let $x\\sim N\\left(0,1\\right)$. If $x_{n}=x+1/n$, then\n",
    "$x_{n}\\stackrel{p}{\\to}x$ and of course $x_{n}\\stackrel{d}{\\to}x$.\n",
    "However, if $x_{n}=-x+1/n$, or $x_{n}=y+1/n$ where\n",
    "$y\\sim N\\left(0,1\\right)$ is independent of $x$, then\n",
    "$x_{n}\\stackrel{d}{\\to}x$ but $x_{n}\\stackrel{p}{\\nrightarrow}x$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1004464",
   "metadata": {},
   "source": [
    "**Example**\n",
    "\n",
    "$(x_{n})$ is a sequence of binary random variables: $x_{n}=n$ with\n",
    "probability $1/\\sqrt{n}$, and $x_{n}=0$ with probability $1-1/\\sqrt{n}$.\n",
    "Then $x_{n}\\stackrel{d}{\\to}x=0.$ Because\n",
    "\n",
    "$$\n",
    "F_{n}\\left(a\\right)=\\begin{cases}\n",
    "0 & a<0\\\\\n",
    "1-1/\\sqrt{n} & 0\\leq a\\leq n\\\\\n",
    "1 & a\\geq n\n",
    "\\end{cases}.\n",
    "$$\n",
    "\n",
    "Let\n",
    "$F \\left(a\\right)=\\begin{cases} 0, & a<0\\\\ 1 & a\\geq0 \\end{cases}$.\n",
    "It is easy to verify that $F_{n}\\left(a\\right)$ converges to\n",
    "$F\\left(a\\right)$ *pointwisely* on each point in $\\mathbb{R}\\backslash \\{0\\}$,\n",
    "where $F\\left(a\\right)$ is continuous.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36affe64",
   "metadata": {},
   "source": [
    "\n",
    "So far we have talked about convergence of scalar variables. These three\n",
    "modes of convergence can be easily generalized to finite-dimensional random vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b1a99f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## Law of Large Numbers\n",
    "\n",
    "Law of large numbers (LLN) is a collection of statements about\n",
    "convergence in probability of the sample average to its population\n",
    "counterpart. The basic form of LLN is:\n",
    "\n",
    "$$\n",
    "\\frac{1}{n}\\sum_{i=1}^{n}(x_{i}-E[x_{i}])\\stackrel{p}{\\to}0\n",
    "$$ \n",
    "\n",
    "as $n\\to\\infty$. Various versions of LLN work under different assumptions\n",
    "about moment restrictions and/or dependence of the underlying random\n",
    "variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1a10c7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "### Cherbyshev LLN\n",
    "\n",
    "We illustrate LLN by the simple example of Chebyshev LLN. It utilizes the *Chebyshev\n",
    "inequality*.\n",
    "\n",
    "The Chebyshev inequality is a special case of the *Markov inequality*.\n",
    "\n",
    "-   *Markov inequality*: If a random variable $x$ has a finite $r$-th\n",
    "    absolute moment $E\\left[\\left|x\\right|^{r}\\right]<\\infty$ for some\n",
    "    $r\\ge1$, then we have\n",
    "    $P\\left\\{ \\left|x\\right|>\\varepsilon\\right\\} \\leq E\\left[\\left|x\\right|^{r}\\right]/\\varepsilon^{r}$\n",
    "    any constant $\\varepsilon>0$. \n",
    "\n",
    "$$\n",
    "\\begin{aligned}E\\left[\\left|x\\right|^{r}\\right] & =\\int_{\\left|x\\right|>\\varepsilon}\\left|x\\right|^{r}dF_{X}+\\int_{\\left|x\\right|\\leq\\varepsilon}\\left|x\\right|^{r}dF_{X}\\\\\n",
    " & \\geq\\int_{\\left|x\\right|>\\varepsilon}\\left|x\\right|^{r}dF_{X}\\\\\n",
    " & \\geq\\varepsilon^{r}\\int_{\\left|x\\right|>\\varepsilon}dF_{X}=\\varepsilon^{r}P\\left\\{ \\left|x\\right|>\\varepsilon\\right\\} .\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Rearrange the above inequality and we obtain the Markov\n",
    "inequality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc23dcc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "Let the *partial sum* $S_{n}=\\sum_{i=1}^{n}x_{i}$ where $x_i$ are independently and identically distributed (i.i.d.). Let \n",
    "$\\mu=E\\left[x_{1}\\right]$ and\n",
    "$\\sigma^{2}=\\mathrm{var}\\left[x_{1}\\right]$. We apply the Chebyshev\n",
    "inequality to the sample mean\n",
    "$y_{n}:=\\bar{x}-\\mu=n^{-1}\\left(S_{n}-E\\left[S_{n}\\right]\\right)$. We have\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P\\left\\{ \\left|y_{n}\\right|\\geq\\varepsilon\\right\\}  & =P\\left\\{ n^{-1}\\left|S_{n}-E\\left[S_{n}\\right]\\right|\\geq\\varepsilon\\right\\} \\\\\n",
    " & \\leq E\\left[\\left(n^{-1}\\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)\\right)^{2}\\right]/\\varepsilon^{2} \\\\\n",
    " & =\\left(n\\varepsilon\\right)^{-2}  E\\left[\\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)^{2}\\right] \\\\\n",
    " & = \\frac{1} {n\\varepsilon^2} \\mathrm{var}\\left(x_{1}\\right).\n",
    "\\end{aligned}\n",
    "$$\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ac806c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This result gives the Chebyshev LLN:\n",
    "\n",
    "-   Chebyshev LLN: If $\\left(x_{1},\\ldots,x_{n}\\right)$ is a sample of\n",
    "    iid observations with $E\\left[x_{1}\\right]=\\mu$ and\n",
    "    $\\sigma^{2}=\\mathrm{var}\\left[x_{1}\\right]<\\infty$, then\n",
    "    $\\frac{1}{n}\\sum_{i=1}^{n}x_{i}\\stackrel{p}{\\to}\\mu.$\n",
    "\n",
    "Another useful LLN is the *Kolmogorov LLN*. Since its derivation\n",
    "requires more advanced knowledge of probability theory, we state the\n",
    "result without proof.\n",
    "\n",
    "-   Kolmogorov LLN: If $\\left(x_{1},\\ldots,x_{n}\\right)$ is a sample of\n",
    "    iid observations and $E\\left[x_{1}\\right]=\\mu$ exists, then\n",
    "    $\\frac{1}{n}\\sum_{i=1}^{n}x_{i}\\stackrel{p}{\\to}\\mu$.\n",
    "\n",
    "Compared with the Chebyshev LLN, the Kolmogorov LLN only requires the\n",
    "existence of the population mean, but not any higher moments. On the\n",
    "other hand, iid is essential for the Kolmogorov LLN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a67e98",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Example** \n",
    "\n",
    "This script demonstrates LLN along with the underlying assumptions.\n",
    "Consider three distributions: standard normal $N\\left(0,1\\right)$,\n",
    "$t\\left(2\\right)$ (zero mean, infinite variance), and the Cauchy\n",
    "distribution (no moments exist). We plot paths of the sample average\n",
    "with $n=2^{1},2^{2},\\ldots,2^{20}$. We will see that the sample averages\n",
    "of $N\\left(0,1\\right)$ and $t\\left(2\\right)$ converge, but that of the\n",
    "Cauchy distribution does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5879e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm, t, cauchy\n",
    "\n",
    "def sample_mean(n, distribution):\n",
    "    \"\"\"\n",
    "    This function calculates the sample mean for a given distribution.\n",
    "    \n",
    "    Parameters:\n",
    "    - n: Number of samples.\n",
    "    - distribution: Type of distribution ('normal', 't2', or 'cauchy').\n",
    "    \n",
    "    Returns:\n",
    "    - The mean of the generated samples.\n",
    "    \"\"\"\n",
    "    if distribution == \"normal\":\n",
    "        y = norm.rvs(size=n)\n",
    "    elif distribution == \"t2\":\n",
    "        y = t.rvs(df=2, size=n)\n",
    "    elif distribution == \"cauchy\":\n",
    "        y = cauchy.rvs(size=n)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported distribution\")\n",
    "    \n",
    "    return np.mean(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159ba664",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This function plots the sample mean over the path of geometrically increasing sample sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce6a562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, t, cauchy\n",
    "\n",
    "def LLN_plot(distribution):\n",
    "    NN = 2**np.arange(1, 21)  # Sample sizes\n",
    "    ybar = np.zeros((len(NN), 3))\n",
    "    for rr in range(3):\n",
    "        for ii, n in enumerate(NN):\n",
    "            ybar[ii, rr] = sample_mean(n, distribution)\n",
    "    \n",
    "    for i in range(3):\n",
    "        plt.plot(NN, ybar[:, i], label=f'Sample Path {i+1}')\n",
    "    plt.axhline(0, color='grey', linestyle='--')\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Sample Size (log scale)')\n",
    "    plt.ylabel('Sample Mean')\n",
    "    plt.title(f'Law of Large Numbers - {distribution.capitalize()} Distribution')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# np.random.seed(2024-7-25) # Set seed for reproducibility\n",
    "\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "LLN_plot(\"normal\")\n",
    "LLN_plot(\"t2\")\n",
    "LLN_plot(\"cauchy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c1d65f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## Central Limit Theorem\n",
    "\n",
    "The central limit theorem (CLT) is a collection of statements\n",
    "about the convergence in distribution to a stable distribution. The\n",
    "limiting distribution is usually the Gaussian distribution. \n",
    "\n",
    "<!-- The basic\n",
    "form of the CLT is:\n",
    "\n",
    "-   *Under some conditions to be spelled out*, the sample average of\n",
    "    *zero-mean* random variables $\\left(x_{1},\\ldots,x_{n}\\right)$\n",
    "    multiplied by $\\sqrt{n}$ satisfies\n",
    "\n",
    "    $$\\frac{1}{\\sqrt{n}}\\sum_{i=1}^{n}x_{i}\\stackrel{d}{\\to}N\\left(0,\\sigma^{2}\\right)$$\n",
    "    \n",
    "    as $n\\to\\infty$. -->\n",
    "\n",
    "Various versions of CLT work under different assumptions about the\n",
    "random variables. *Lindeberg-Levy CLT* is the simplest version.\n",
    "\n",
    "-   If the sample $\\left(x_{1},\\ldots,x_{n}\\right)$ is iid,\n",
    "    $E\\left[x_{1}\\right]=0$ and\n",
    "    $\\mathrm{var}\\left[x_{1}\\right]=\\sigma^{2}<\\infty$, then\n",
    "    $\\frac{1}{\\sqrt{n}}\\sum_{i=1}^{n}x_{i}\\stackrel{d}{\\to}N\\left(0,\\sigma^{2}\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012222b1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "This is a simulated example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d5cc8d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Example**\n",
    "\n",
    "$\\chi^2(2)$ distribution with sample sizes $n=2$, $10$, and $100$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ef818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, chi2\n",
    "\n",
    "def Z_fun(n, distribution):\n",
    "    if distribution == \"normal\":\n",
    "        z = np.sqrt(n) * np.mean(np.random.normal(size=n))\n",
    "    elif distribution == \"chisq2\":\n",
    "        df = 2\n",
    "        x = np.random.chisquare(df, n)\n",
    "        z = np.sqrt(n) * (np.mean(x) - df) / np.sqrt(2*df)\n",
    "    return z\n",
    "\n",
    "def CLT_plot(n, distribution):\n",
    "    Rep = 10000\n",
    "    ZZ = np.array([Z_fun(n, distribution) for _ in range(Rep)])\n",
    "    \n",
    "    xbase = np.linspace(-4.0, 4.0, 100)\n",
    "    plt.hist(ZZ, bins=100, density=True, alpha=0.75, \n",
    "             label=f'Sample Size {n}', color='blue')\n",
    "    plt.plot(xbase, norm.pdf(xbase), color='red', label='Standard Normal')\n",
    "    plt.xlim([np.min(xbase), np.max(xbase)])\n",
    "    plt.title(f\"Histogram with sample size {n}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "CLT_plot(2, \"chisq2\")\n",
    "CLT_plot(10, \"chisq2\")\n",
    "CLT_plot(100, \"chisq2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a39eb0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## Tools for Transformations\n",
    "\n",
    "-   Continuous mapping theorem 1: If $y_{n}\\stackrel{p}{\\to}a$ and\n",
    "    $f\\left(\\cdot\\right)$ is continuous at $a$, then\n",
    "    $f\\left(y_{n}\\right)\\stackrel{p}{\\to}f\\left(a\\right)$.\n",
    "\n",
    "-   Continuous mapping theorem 2: If $z_{n}\\stackrel{d}{\\to} z$ and\n",
    "    $f\\left(\\cdot\\right)$ is continuous almost surely on the support of\n",
    "    $z$, then $f\\left(z_{n}\\right)\\stackrel{d}{\\to}f\\left(z\\right)$.\n",
    "\n",
    "-   Slutsky’s theorem: If \n",
    "    $y_{n}\\stackrel{p}{\\to}a$ and $z_{n}\\stackrel{d}{\\to}z$ and, then\n",
    "\n",
    "    -   $z_{n}+y_{n}\\stackrel{d}{\\to}z+a$\n",
    "\n",
    "    -   $z_{n}y_{n}\\stackrel{d}{\\to}az$\n",
    "\n",
    "    -   $z_{n}/y_{n}\\stackrel{d}{\\to}z/a$ if $a\\neq0$.\n",
    "\n",
    "Slutsky’s theorem consists of special cases of the continuous mapping\n",
    "theorem 2. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b953d3b4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
